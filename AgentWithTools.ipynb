{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panda-sas/ai-agent/blob/v1/AgentWithTools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install litellm\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ],
      "metadata": {
        "id": "KEYrzG2vB8Ip"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwe2eeOQB0cC",
        "outputId": "78466036-7bc8-4c07-b78e-17709894b1aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like me to do? Look for files\n",
            "Agent thinking...\n",
            "Agent response: To check for any available files, I will list all files in the current directory first.\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"list_files\",\n",
            "    \"args\": {}\n",
            "}\n",
            "```\n",
            "Action result: {'result': ['.config', 'sample_data']}\n",
            "Agent thinking...\n",
            "Agent response: The response indicates that there are two items listed: one seems to be a configuration file or directory (\".config\"), while the other is a directory (\"sample_data\"). Neither appear to be a standard readable content file. If you are looking for specific document content, these might not provide much unless you want specific data related information typically stored in these files.\n",
            "\n",
            "If you have any particular request for a specific file or directory action, let me know! Otherwise, based on the current files available, here's the situation: we don't have a conventional document or content file to read from this list.\n",
            "\n",
            "I'll make a final summary for you.\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"terminate\",\n",
            "    \"args\": {\n",
            "        \"message\": \"I found a configuration directory and a data directory. There are no standard readable files here.\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "I found a configuration directory and a data directory. There are no standard readable files here.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "def extract_markdown_block(response: str, block_type: str = \"json\") -> str:\n",
        "    \"\"\"Extract code block from response\"\"\"\n",
        "\n",
        "    if not '```' in response:\n",
        "        return response\n",
        "\n",
        "    code_block = response.split('```')[1].strip()\n",
        "\n",
        "    if code_block.startswith(block_type):\n",
        "        code_block = code_block[len(block_type):].strip()\n",
        "\n",
        "    return code_block\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get a response.\"\"\"\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def parse_action(response: str) -> Dict:\n",
        "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
        "    try:\n",
        "        response = extract_markdown_block(response, \"action\")\n",
        "        response_json = json.loads(response)\n",
        "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
        "            return response_json\n",
        "        else:\n",
        "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
        "\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Define system instructions (Agent Rules)\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "Available tools:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"list_files\": {\n",
        "        \"description\": \"Lists all files in the current directory.\",\n",
        "        \"parameters\": {}\n",
        "    },\n",
        "    \"read_file\": {\n",
        "        \"description\": \"Reads the content of a file.\",\n",
        "        \"parameters\": {\n",
        "            \"file_name\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The name of the file to read.\"\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"terminate\": {\n",
        "        \"description\": \"Ends the agent loop and provides a summary of the task.\",\n",
        "        \"parameters\": {\n",
        "            \"message\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Summary message to return to the user.\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\n",
        "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
        "\n",
        "Important!!! Every response MUST have an action.\n",
        "You must ALWAYS respond in this format:\n",
        "\n",
        "<Stop and think step by step. Parameters map to args. Insert a rich description of your step by step thoughts here.>\n",
        "\n",
        "```action\n",
        "{\n",
        "    \"tool_name\": \"insert tool_name\",\n",
        "    \"args\": {...fill in any required arguments here...}\n",
        "}\n",
        "```\"\"\"\n",
        "}]\n",
        "\n",
        "# Initialize agent parameters\n",
        "iterations = 0\n",
        "max_iterations = 10\n",
        "\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "# The Agent Loop\n",
        "while iterations < max_iterations:\n",
        "    # 1. Construct prompt: Combine agent rules with memory\n",
        "    prompt = agent_rules + memory\n",
        "\n",
        "    # 2. Generate response from LLM\n",
        "    print(\"Agent thinking...\")\n",
        "    response = generate_response(prompt)\n",
        "    print(f\"Agent response: {response}\")\n",
        "\n",
        "    # 3. Parse response to determine action\n",
        "    action = parse_action(response)\n",
        "    result = \"Action executed\"\n",
        "\n",
        "    if action[\"tool_name\"] == \"list_files\":\n",
        "        result = {\"result\": list_files()}\n",
        "    elif action[\"tool_name\"] == \"read_file\":\n",
        "        result = {\"result\": read_file(action[\"args\"][\"file_name\"])}\n",
        "    elif action[\"tool_name\"] == \"error\":\n",
        "        result = {\"error\": action[\"args\"][\"message\"]}\n",
        "    elif action[\"tool_name\"] == \"terminate\":\n",
        "        print(action[\"args\"][\"message\"])\n",
        "        break\n",
        "    else:\n",
        "        result = {\"error\": \"Unknown action: \" + action[\"tool_name\"]}\n",
        "\n",
        "    print(f\"Action result: {result}\")\n",
        "\n",
        "    # 5. Update memory with response and results\n",
        "    memory.extend([\n",
        "        {\"role\": \"assistant\", \"content\": response},\n",
        "        {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "    ])\n",
        "\n",
        "    # 6. Check termination condition\n",
        "    if action[\"tool_name\"] == \"terminate\":\n",
        "        break\n",
        "\n",
        "    iterations += 1\n"
      ]
    }
  ]
}